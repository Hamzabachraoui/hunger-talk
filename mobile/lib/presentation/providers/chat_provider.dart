import 'package:flutter/foundation.dart';
import '../../data/models/chat_message_model.dart';
import '../../data/services/chat_service.dart';

class ChatProvider with ChangeNotifier {
  final ChatService _chatService = ChatService();

  List<ChatMessageModel> _messages = [];
  bool _isLoading = false;
  bool _isSending = false;
  String? _error;

  List<ChatMessageModel> get messages => _messages;
  bool get isLoading => _isLoading;
  bool get isSending => _isSending;
  String? get error => _error;

  Future<void> loadHistory() async {
    _isLoading = true;
    _error = null;
    notifyListeners();

    try {
      debugPrint('üí¨ [CHAT PROVIDER] Chargement de l\'historique...');
      final backendMessages = await _chatService.getHistory();
      
      // Convertir chaque message backend (qui contient message + response) en deux messages s√©par√©s
      _messages = [];
      for (final backendMsg in backendMessages) {
        // Ajouter le message utilisateur
        if (backendMsg.message.isNotEmpty) {
          _messages.add(ChatMessageModel(
            id: '${backendMsg.id}_user',
            message: backendMsg.message,
            isUser: true,
            timestamp: backendMsg.timestamp,
          ));
        }
        
        // Ajouter la r√©ponse IA
        if (backendMsg.response != null && backendMsg.response!.isNotEmpty) {
          _messages.add(ChatMessageModel(
            id: '${backendMsg.id}_ai',
            message: backendMsg.response!,
            isUser: false,
            timestamp: backendMsg.timestamp,
          ));
        }
      }
      
      // Trier par timestamp pour avoir l'ordre chronologique (les plus anciens en premier)
      _messages.sort((a, b) => a.timestamp.compareTo(b.timestamp));
      
      debugPrint('‚úÖ [CHAT PROVIDER] ${_messages.length} message(s) charg√©(s) depuis ${backendMessages.length} conversation(s)');
      _isLoading = false;
      notifyListeners();
    } catch (e, stackTrace) {
      debugPrint('‚ùå [CHAT PROVIDER] Erreur lors du chargement: $e');
      debugPrint('   Stack: $stackTrace');
      _error = e.toString();
      _isLoading = false;
      notifyListeners();
    }
  }

  Future<bool> sendMessage(String message) async {
    _isSending = true;
    _error = null;
    
    // Ajouter le message utilisateur imm√©diatement
    final userMessage = ChatMessageModel(
      id: DateTime.now().millisecondsSinceEpoch.toString(),
      message: message,
      isUser: true,
      timestamp: DateTime.now(),
    );
    _messages.add(userMessage);
    notifyListeners();

    // Cr√©er le message IA vide qui sera mis √† jour progressivement avec le streaming
    final aiMessageId = (DateTime.now().millisecondsSinceEpoch + 1).toString();
    final aiMessage = ChatMessageModel(
      id: aiMessageId,
      message: '',
      isUser: false,
      timestamp: DateTime.now(),
    );
    _messages.add(aiMessage);
    notifyListeners();

    try {
      debugPrint('üí¨ [CHAT PROVIDER] Envoi du message avec streaming...');
      
      final response = await _chatService.sendMessage(
        message,
        onChunk: (partialResponse) {
          // Mettre √† jour le message IA progressivement
          final index = _messages.indexWhere((m) => m.id == aiMessageId);
          if (index != -1) {
            _messages[index] = ChatMessageModel(
              id: aiMessageId,
              message: partialResponse,
              isUser: false,
              timestamp: _messages[index].timestamp,
            );
            notifyListeners();
          }
        },
      );
      
      // Mettre √† jour avec la r√©ponse finale (au cas o√π il y aurait un dernier chunk)
      final finalIndex = _messages.indexWhere((m) => m.id == aiMessageId);
      if (finalIndex != -1 && _messages[finalIndex].message != response) {
        _messages[finalIndex] = ChatMessageModel(
          id: aiMessageId,
          message: response,
          isUser: false,
          timestamp: _messages[finalIndex].timestamp,
        );
        notifyListeners();
      }
      
      debugPrint('‚úÖ [CHAT PROVIDER] Message envoy√© avec succ√®s');
      
      // Recharger l'historique pour obtenir les IDs du backend et s'assurer que tout est synchronis√©
      // Cela remplace les messages temporaires par les messages sauvegard√©s du backend
      try {
        await loadHistory();
        debugPrint('‚úÖ [CHAT PROVIDER] Historique recharg√© apr√®s envoi');
      } catch (e) {
        debugPrint('‚ö†Ô∏è [CHAT PROVIDER] Erreur lors du rechargement de l\'historique: $e');
        // Ne pas faire √©chouer l'envoi si le rechargement √©choue
      }
      
      _isSending = false;
      notifyListeners();
      return true;
    } catch (e, stackTrace) {
      debugPrint('‚ùå [CHAT PROVIDER] Erreur lors de l\'envoi: $e');
      debugPrint('   Stack: $stackTrace');
      
      // Supprimer le message IA vide en cas d'erreur
      _messages.removeWhere((m) => m.id == aiMessageId);
      
      _error = e.toString();
      _isSending = false;
      notifyListeners();
      return false;
    }
  }

  void clearError() {
    _error = null;
    notifyListeners();
  }
}

