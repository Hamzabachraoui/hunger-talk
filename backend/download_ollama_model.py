"""
Script pour t√©l√©charger le mod√®le Ollama llama3.1:8b
"""
import requests
import json
import sys

OLLAMA_URL = "http://localhost:11434"

def download_model(model_name: str = "llama3.1:8b"):
    """T√©l√©charger un mod√®le Ollama"""
    print(f"üì• T√©l√©chargement du mod√®le {model_name}...")
    print("‚è≥ Cela peut prendre plusieurs minutes (le mod√®le fait ~4.7 GB)...")
    print()
    
    try:
        # V√©rifier que Ollama est disponible
        response = requests.get(f"{OLLAMA_URL}/api/tags", timeout=5)
        if response.status_code != 200:
            print("‚ùå Ollama n'est pas disponible. Assurez-vous qu'Ollama est d√©marr√©.")
            return False
        
        # T√©l√©charger le mod√®le
        payload = {"name": model_name}
        response = requests.post(
            f"{OLLAMA_URL}/api/pull",
            json=payload,
            stream=True,
            timeout=None  # Pas de timeout pour le t√©l√©chargement
        )
        
        if response.status_code != 200:
            print(f"‚ùå Erreur lors du t√©l√©chargement: {response.status_code}")
            print(response.text)
            return False
        
        # Afficher la progression
        print("üìä Progression du t√©l√©chargement:")
        print("-" * 60)
        
        for line in response.iter_lines():
            if line:
                try:
                    data = json.loads(line)
                    
                    if "status" in data:
                        status = data["status"]
                        if "digesting" in status or "pulling" in status:
                            print(f"   {status}")
                        elif "downloading" in status:
                            if "completed" in data and "total" in data:
                                completed = data.get("completed", 0)
                                total = data.get("total", 0)
                                if total > 0:
                                    percent = (completed / total) * 100
                                    print(f"   T√©l√©chargement: {percent:.1f}% ({completed}/{total} bytes)")
                    
                    if data.get("status") == "success":
                        print("\n‚úÖ Mod√®le t√©l√©charg√© avec succ√®s !")
                        return True
                        
                except json.JSONDecodeError:
                    continue
        
        print("\n‚úÖ T√©l√©chargement termin√© !")
        return True
        
    except requests.exceptions.ConnectionError:
        print("‚ùå Impossible de se connecter √† Ollama.")
        print("   Assurez-vous qu'Ollama est d√©marr√© et accessible sur http://localhost:11434")
        return False
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return False

def check_model(model_name: str = "llama3.1:8b"):
    """V√©rifier si le mod√®le est install√©"""
    try:
        response = requests.get(f"{OLLAMA_URL}/api/tags", timeout=5)
        if response.status_code == 200:
            data = response.json()
            models = [model.get("name", "") for model in data.get("models", [])]
            
            # V√©rifier si le mod√®le exact ou une variante est install√©e
            for model in models:
                if model_name in model or model in model_name:
                    print(f"‚úÖ Mod√®le trouv√©: {model}")
                    return True
            
            print(f"‚ùå Mod√®le {model_name} non trouv√©.")
            print(f"   Mod√®les install√©s: {', '.join(models) if models else 'Aucun'}")
            return False
    except Exception as e:
        print(f"‚ùå Erreur lors de la v√©rification: {e}")
        return False

def main():
    model_name = "llama3.1:8b"
    
    print("=" * 60)
    print("  T√âL√âCHARGEMENT DU MOD√àLE OLLAMA")
    print("=" * 60)
    print()
    
    # V√©rifier d'abord si le mod√®le existe d√©j√†
    print("üîç V√©rification des mod√®les install√©s...")
    if check_model(model_name):
        print("\n‚úÖ Le mod√®le est d√©j√† install√© !")
        return 0
    
    print()
    
    # T√©l√©charger le mod√®le
    success = download_model(model_name)
    
    if success:
        print()
        print("=" * 60)
        print("‚úÖ T√âL√âCHARGEMENT R√âUSSI !")
        print("=" * 60)
        print()
        print("üí° Vous pouvez maintenant tester l'API chat:")
        print("   http://localhost:8000/docs")
        print()
        return 0
    else:
        print()
        print("=" * 60)
        print("‚ùå √âCHEC DU T√âL√âCHARGEMENT")
        print("=" * 60)
        print()
        print("üí° V√©rifiez que:")
        print("   1. Ollama est d√©marr√©")
        print("   2. Vous avez une connexion Internet")
        print("   3. Vous avez assez d'espace disque (~5 GB)")
        return 1

if __name__ == "__main__":
    sys.exit(main())

